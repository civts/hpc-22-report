\section{Problem analysis}
\label{sec:problem_analysis}

% description of the problem
The na\"ive solution to this problem would be to take each point
in the plane and calculate the distance between that point and all
the other points. The time complexity for this solution is $\Theta(N^2)$,
where $N\coloneqq|S|$ is the cardinality of the set $S$.

% Better solutions have been proposed, in particular in 1975
% Rabin proposed a stocastic algorithm with an expected run time
% of $O(N)$.

In 1975, Shamos and Hoey proved that the lower bound for the problem is $\Omega(N * log(N))$\cite[ยง2, theorem 1]{closest_pair_definition}. An algorithm with said complexity appears
the following year from Bentley and Shamos \cite{divide_and_conq_3NlgN}.
% in a book by Preparata and Shamos \cite[ยง5.4]{preparata1993computational}.
A new version of that algortihm was proposed in 2006, reducing the time complexity by a factor of two \cite{ge2006improved}.

For the purposes of this research, we decided to implement the version of Bentley and Shamos, which falls into the best category of complexity whilst still keeping the base algorithm relatively simple, aiding the comprehension of the code.
% For this research, we chose to use a divide and conquer approach
% with $O(N*(logN)^2)$ time complexity. We chose it because
% divide and conquer is highly parallelizable so it will be easier
% to exploit the computational power of the HPC cluster.

\subsection{Serial implementation}

We will now focus on the analysis of the divide and conquer algorithm
and its serial implementation.

\subsubsection{Divide}
The first step of the algorithm is the divide operation, i.e.,
split the original problem in sub problems.

The original set of points will be split in two subsets and each
subset will be split in two subsets and so on. This process will be repeated
until we have three or less points in each subset.

\subsubsection{Find the closest pair}
To find the closest pair in each subset we only have to perform
at most three comparisons and select the pair of points with the smallest
distance in the subset.

\subsubsection{Merge}
The merge operation is a crucial part in the algorithm.
The first thing to do is to take two adjacent subsets and compare the distances
found in each subset and take the pair of points with smaller distance. Then we
need to look at the boundary between the two subsets and check the distances of
the pairs where one point belongs to one subset and one point belongs to the other
subset. To check these points we first select the strip of points with $x$ distance smaller
than the current smaller distance, then we sort the selected points by the $y$ coordinate.
Finally, for each point in the strip we calculate the distance between that point and
the $7$ points around it and we compare this distance with the smaller distance found so far.
It can be proven matematically that 7 is the maximum number of points to check since, if there
would be closer points, a smaller distance would have been found in the previous step.
(Decidere se spiegare meglio e/o aggiungere l'immagine)

\subsection{Implementation}
To implement the serial algorithm we started by implementing the \verb+closest_points_divide+
function that takes an array of points already sorted by the x coordinate and split the array in two
halves and recursively computes the distances of each half using the \verb+closest_points_rec+
function. After the distances computation we use the smallest distances to select the points
near the boundary. Then we use the \verb+band_update_result+ to sort these points by the $y$ coordinate
and check the distance between each point and the next 6 points.

% state of the art
